{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Idea\n",
    "\n",
    "### Режимы работы библиотеки:\n",
    "\n",
    "1. На вход ей подается текст и на выход получаем фонемы (разные прочтения)\n",
    "2. На вход подаем фонемы двух типов и получаем их разницу\n",
    "3. Мы подаем текст/фонемы и логиты (вероятности каждой фонемы в каждом звуковом окне) и получаем транскрипцию\n",
    "\n",
    "### Хотим учесть:\n",
    "\n",
    "- cmudict + lextool для первичного преобразования текста в фонемы по словарю/эвристикам\n",
    "- функции для работы с фонемами - трансляция 61-48-39, one-letter-encoding, diff функции и подсчет операций\n",
    "- витерби для третьего режима\n",
    "- эвристики на стыке слов и похожие звуки\n",
    "- сравнение с фонемами тимита\n",
    "- разные варианты произношения слова\n",
    "\n",
    "На будущее:\n",
    "- сравнить с https://github.com/bootphon/phonemizer на различных бэкендах - используют ли они тоже cmudict внутри или какой-то свой фонемайзер\n",
    "- ударения - как отдельных слов так и целиком в предложении\n",
    "\n",
    "### Начальные статы сравнения транскрипций словарных с тимитом:\n",
    "\n",
    "```\n",
    "sum(stats[\"cer\"])/len(stats[\"cer\"])\n",
    "0.24904557704602598\n",
    "\n",
    "sorted(stats[\"cer\"])[int(len(stats[\"cer\"])/2)]\n",
    "0.25\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Перевести разметку тимита при помощи cmudict\n",
    "\n",
    "import torch\n",
    "from glob import glob\n",
    "from soundfile import read as read_sound\n",
    "\n",
    "import editdistance\n",
    "\n",
    "CMU_DICT = \"/home/gazay/code/phns/phns/vendor/cmudict/cmudict.dict\"\n",
    "PHNS_MAP = \"/home/gazay/code/berloga-dl/accent2/lenin_accent/utils/phones.61-48-39.map\"\n",
    "\n",
    "\n",
    "cmu = {}\n",
    "for word in open(CMU_DICT).read().split(\"\\n\"):\n",
    "    word_parts = word.split(' ')\n",
    "    cmu[word_parts[0]] = [''.join(filter(lambda x: not x.isdigit(), phn.lower())) for phn in word_parts[1:]]\n",
    "    \n",
    "class TimitDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.wavs = glob(path + '/*/*/*/*.wav')\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.wavs)\n",
    "    \n",
    "    def __read_phns__(self, path):\n",
    "        raw_phns = open(path).read()\n",
    "        phns = [phn.split(' ')[-1] for phn in raw_phns.split('\\n') if len(phn)]\n",
    "        phns = remap(phns)\n",
    "        phns = [phn for phn in phns if phn != 'sil']\n",
    "        return phns\n",
    "    \n",
    "    def __read_txt__(self, path):\n",
    "        raw_text = open(path).read()\n",
    "        return raw_text.split(' ', 2)[-1]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        wav_path = self.wavs[idx]\n",
    "        phn_path = wav_path.replace('.WAV.wav', '.PHN')\n",
    "        txt_path = wav_path.replace('.WAV.wav', '.TXT')\n",
    "        wav = read_sound(wav_path)\n",
    "        phns = self.__read_phns__(phn_path)\n",
    "        text = self.__read_txt__(txt_path)\n",
    "        _text = text.lower()   \\\n",
    "            .replace('.', '')  \\\n",
    "            .replace(\"\\n\", '') \\\n",
    "            .replace('?', '')  \\\n",
    "            .replace(',', '')  \\\n",
    "            .replace(';', '')  \\\n",
    "            .replace(':', '')  \\\n",
    "            .replace('\"', '')  \\\n",
    "            .replace('!', '')  \\\n",
    "            .replace('-', ' ') \\\n",
    "            .split(' ')\n",
    "        cmu_phns = []\n",
    "        \n",
    "        cer_to_null = False\n",
    "        for word in _text:\n",
    "            if word not in cmu:\n",
    "                print(\"word not in dict: \", word)\n",
    "                cer_to_null = True\n",
    "                continue\n",
    "            cmu_phns.extend(cmu[word])\n",
    "        cer = editdistance.eval(phns, cmu_phns)/len(phns)\n",
    "        if cer_to_null:\n",
    "            cer = 0\n",
    "        \n",
    "        _phns = single_char_encode(phns)\n",
    "        _cmu_phns = single_char_encode(cmu_phns)\n",
    "        return {\"wav\": wav, \"orig_phns\": phns, \"orig_cmu_phns\": cmu_phns, \"phns\": _phns, \"text\": text, \"cmu_phns\": _cmu_phns, \"cer\": cer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for unknown words http://www.speech.cs.cmu.edu/tools/lextool.html\n",
    "\n",
    "import os\n",
    "import IPython\n",
    "from diff_match_patch import diff_match_patch\n",
    "DIFFER = diff_match_patch()\n",
    "\n",
    "def show_diff(r, t):\n",
    "    html_diffs = DIFFER.diff_main(r, t)\n",
    "    display(IPython.display.HTML(DIFFER.diff_prettyHtml(html_diffs)))\n",
    "    \n",
    "def diff(item):\n",
    "    print(item[\"text\"])\n",
    "    show_diff(item[\"phns\"], item[\"cmu_phns\"])\n",
    "    \n",
    "def load_phone_map():\n",
    "    with open(PHNS_MAP, 'r') as fid:\n",
    "        lines = (l.strip().split() for l in fid)\n",
    "        lines = [l for l in lines if len(l) == 3]\n",
    "    m61_48 = {l[0] : l[1] for l in lines}\n",
    "    m48_39 = {l[1] : l[2] for l in lines}\n",
    "    return m61_48, m48_39\n",
    "\n",
    "m61_48, m48_39 = load_phone_map()\n",
    "\n",
    "def remap_48_to_39(data):\n",
    "    return [m48_39[p] for p in data if p in m48_39]\n",
    "\n",
    "def remap_61_to_48(data):\n",
    "    return [m61_48[p] for p in data if p in m61_48]\n",
    "\n",
    "# TODO: document phonems in different models/datasets\n",
    "def remap(data):\n",
    "    result = []\n",
    "    for phn in data:\n",
    "        # dx is missing from awni 39 phonemes\n",
    "        if phn == 'dx':\n",
    "            result.append('d')\n",
    "        elif phn == 'sil': # in case we override phoneme target and use SIL symbol\n",
    "            result.append(phn)\n",
    "        elif phn != 'q':\n",
    "            result.append(m48_39[m61_48[phn]])\n",
    "    return result\n",
    "\n",
    "def single_char_encode(phns):\n",
    "    return ''.join([one_letter_encoding[phn] for phn in phns])\n",
    "\n",
    "one_letter_encoding = {\n",
    "    'aa': 'a',\n",
    "    'ae': '@',\n",
    "    'ah': 'A',\n",
    "    'ao': 'c',\n",
    "    'aw': 'W',\n",
    "    'ax': 'x',\n",
    "    'ay': 'Y',\n",
    "    'b': 'b',\n",
    "    'ch': 'C',\n",
    "    'cl': '-',\n",
    "    'd': 'd',\n",
    "    'dh': 'D',\n",
    "    'dx': 'F',\n",
    "    'eh': 'E',\n",
    "    'el': 'L',\n",
    "    'en': 'N',\n",
    "    'epi': '=',\n",
    "    'er': 'R',\n",
    "    'ey': 'e',\n",
    "    'f': 'f',\n",
    "    'g': 'g',\n",
    "    'hh': 'h',\n",
    "    'ih': 'I',\n",
    "    'ix': 'X',\n",
    "    'iy': 'i',\n",
    "    'jh': 'J',\n",
    "    'k': 'k',\n",
    "    'l': 'l',\n",
    "    'm': 'm',\n",
    "    'n': 'n',\n",
    "    'ng': 'G',\n",
    "    'ow': 'o',\n",
    "    'oy': 'O',\n",
    "    'p': 'p',\n",
    "    'r': 'r',\n",
    "    's': 's',\n",
    "    'sh': 'S',\n",
    "    'sil': '_',\n",
    "    't': 't',\n",
    "    'th': 'T',\n",
    "    'uh': 'U',\n",
    "    'uw': 'u',\n",
    "    'v': 'v',\n",
    "    'vcl': '+',\n",
    "    'w': 'w',\n",
    "    'y': 'y',\n",
    "    'z': 'z',\n",
    "    'zh': 'Z'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = TimitDataset(path=\"/home/gazay/datasets/TIMIT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Swing your arm as high as you can.\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item = next(iter(ds))\n",
    "item[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item[\"orig_phns\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word not in dict:  motorists'\n",
      "word not in dict:  morphophonemic\n",
      "word not in dict:  nihilistic\n",
      "word not in dict:  radiosterilization\n",
      "word not in dict:  exhusband\n",
      "word not in dict:  somebody'll\n",
      "word not in dict:  smolderingly\n",
      "word not in dict:  geocentricism\n",
      "word not in dict:  unmagnified\n",
      "word not in dict:  stirrin\n",
      "word not in dict:  utopianism\n",
      "word not in dict:  infuriation\n",
      "word not in dict:  preprepared\n",
      "word not in dict:  understandingly\n",
      "word not in dict:  eventualities\n",
      "word not in dict:  micrometeorites\n",
      "word not in dict:  herdin'\n",
      "word not in dict:  responsively\n",
      "word not in dict:  demineralization\n",
      "word not in dict:  herdin'\n",
      "word not in dict:  unwaveringly\n",
      "word not in dict:  cap'n\n",
      "word not in dict:  mournfully\n",
      "word not in dict:  andrei's\n",
      "word not in dict:  autofluorescence\n",
      "word not in dict:  fasciculations\n",
      "word not in dict:  weatherstrip\n",
      "word not in dict:  nonsystematic\n",
      "word not in dict:  traditionalism\n",
      "word not in dict:  chorused\n",
      "word not in dict:  micrometeorite\n",
      "word not in dict:  reupholstering\n",
      "word not in dict:  castorbeans\n"
     ]
    }
   ],
   "source": [
    "stats = {\n",
    "    \"len\": [],\n",
    "    \"cer\": []\n",
    "}\n",
    "\n",
    "for item in ds:\n",
    "    stats[\"len\"].append(len(item[\"phns\"]))\n",
    "    stats[\"cer\"].append(item[\"cer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span>don</span><del style=\"background:#ffe6e6;\">Ch</del><ins style=\"background:#e6ffe6;\">tyu</ins><span>he</span><ins style=\"background:#e6ffe6;\">t</ins><span>miEnim</span><del style=\"background:#ffe6e6;\">a</del><ins style=\"background:#e6ffe6;\">c</ins><span>r</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_diff(item[\"phns\"], item[\"cmu_phns\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24904557704602637"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(stats[\"cer\"])/len(stats[\"cer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(stats[\"cer\"])[int(len(stats[\"cer\"])/2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2631578947368421,\n",
       " 0.3548387096774194,\n",
       " 0.23809523809523808,\n",
       " 0.17857142857142858,\n",
       " 0.1111111111111111,\n",
       " 0.18181818181818182,\n",
       " 0.1,\n",
       " 0.225,\n",
       " 0.25,\n",
       " 0.19148936170212766]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats[\"cer\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmu['spend']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Swing your arm as high as you can.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span>swIGy</span><del style=\"background:#ffe6e6;\">R</del><ins style=\"background:#e6ffe6;\">cr</ins><span>arm</span><del style=\"background:#ffe6e6;\">E</del><ins style=\"background:#e6ffe6;\">@</ins><span>zhY</span><del style=\"background:#ffe6e6;\">I</del><ins style=\"background:#e6ffe6;\">@</ins><span>z</span><ins style=\"background:#e6ffe6;\">y</ins><span>uk@n</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "item = ds.__getitem__(0)\n",
    "diff(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'swIGyRarmEzhYIzuk@n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item['phns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s',\n",
       " 'w',\n",
       " 'ih',\n",
       " 'ng',\n",
       " 'y',\n",
       " 'er',\n",
       " 'aa',\n",
       " 'r',\n",
       " 'm',\n",
       " 'eh',\n",
       " 'z',\n",
       " 'hh',\n",
       " 'ay',\n",
       " 'ih',\n",
       " 'z',\n",
       " 'uw',\n",
       " 'k',\n",
       " 'ae',\n",
       " 'n']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item['orig_phns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6300 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import phns\n",
    "\n",
    "TIMIT_ROOT = \"/home/gazay/datasets/TIMIT\"\n",
    "\n",
    "data = []\n",
    "for text_path in glob(TIMIT_ROOT + \"/*/*/*/*.TXT\"):\n",
    "    phns_path = text_path.replace(\".TXT\", \".PHN\")\n",
    "    text = open(text_path).read().split(\" \", 2)[-1]\n",
    "    _phns = open(phns_path).read().split(\"\\n\")\n",
    "    _phns = [phn.split(\" \")[-1] for phn in _phns if phn]\n",
    "    _phns = phns.utils.remap(_phns)\n",
    "\n",
    "    data.append({\"text\": text, \"phns\": _phns})\n",
    "\n",
    "cers = []\n",
    "for _item in tqdm(data):\n",
    "    calculated_phns_variants = phns.from_text(_item[\"text\"])\n",
    "    if not calculated_phns_variants:\n",
    "        continue\n",
    "\n",
    "    best = phns.closest(_item[\"phns\"], calculated_phns_variants)\n",
    "    cers.append(best[\"cer\"])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'She had your dark suit in greasy wash water all year.\\n',\n",
       " 'phns': ['sil',\n",
       "  'sh',\n",
       "  'iy',\n",
       "  'hh',\n",
       "  'ae',\n",
       "  'sil',\n",
       "  'd',\n",
       "  'y',\n",
       "  'er',\n",
       "  'sil',\n",
       "  'd',\n",
       "  'aa',\n",
       "  'r',\n",
       "  'sil',\n",
       "  'k',\n",
       "  's',\n",
       "  'uw',\n",
       "  'sil',\n",
       "  't',\n",
       "  'ih',\n",
       "  'n',\n",
       "  'sil',\n",
       "  'g',\n",
       "  'r',\n",
       "  'iy',\n",
       "  's',\n",
       "  'iy',\n",
       "  'w',\n",
       "  'aa',\n",
       "  'sh',\n",
       "  'sil',\n",
       "  'w',\n",
       "  'aa',\n",
       "  'd',\n",
       "  'er',\n",
       "  'aa',\n",
       "  'l',\n",
       "  'y',\n",
       "  'ih',\n",
       "  'er',\n",
       "  'sil']}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_item"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
